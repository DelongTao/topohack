{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/topohack/data\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-755bb08027db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "#this downloads the shapefiles you need to figure out where your boundbox is within the Arctic DEM\n",
    "import zipfile, urllib.request, shutil\n",
    "%cd ../../data/\n",
    "\n",
    "url = 'http://data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/indexes/ArcticDEM_Tile_Index_Rel7.zip'\n",
    "file_name = 'ArcticDEM_Tile_Index.zip'\n",
    "\n",
    "with urllib.request.urlopen(url) as response, open(file_name, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "    with zipfile.ZipFile(file_name) as zf:\n",
    "        zf.extractall()\n",
    "     \n",
    "%mkdir ArcticDEM\n",
    "%mv ArcticDEM_Tile_Index.zip ArcticDEM\n",
    "!unzip ArcticDEM_Tile_Index.zip #THIS DOESNT WORK RIGHT NOW\n",
    "\n",
    "#ignore the error, it works even though you get an error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bd556588d253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mintersection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# tiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "#read in bbox and convert to polar stereographic, to then look at arctic DEM\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "bbox_w = -139\n",
    "bbox_s = 60\n",
    "bbox_e = -138\n",
    "bbox_n = 61\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'Latitude': [bbox_s, bbox_s, bbox_n, bbox_n],\n",
    "     'Longitude': [bbox_w, bbox_e, bbox_e, bbox_w]})\n",
    "\n",
    "bbox = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n",
    "\n",
    "tiles = gpd.read_file(\"ArcticDEM/ArcticDEM_Tile_Index_Rel7.shp\")\n",
    "\n",
    "tiles = tiles.to_crs({'init':'epsg:4326'}) #transform to WGS84\n",
    "\n",
    "\n",
    "#from geopandas.geoseries import *\n",
    "\n",
    "\n",
    "intersection = bbox.intersects(tiles)\n",
    "\n",
    "#I just need to figure out how to figure out where the intersection index is TRUE and then get that index number to compare with tiles\n",
    "\n",
    "\n",
    "# tiles\n",
    "\n",
    "\n",
    "# tiles['tile']\n",
    "\n",
    "# print(intersection)\n",
    "# print(tiles['tile'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/topohack/data\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd ../../data/\n",
    "\n",
    "#tiles['tile']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Tyler Sutterley (05/2019)\n",
    "\n",
    "# adapted and put into Jupyter by M. Truffer (06/2019)\n",
    "# this file is just a subset of the more comprehensive pgc_arcticdem_sync.py to download 2m DEM tiles for the Juneau Icefield\n",
    "\n",
    "#Program to sync ArcticDEM tar files\n",
    "#http://data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/mosaic\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import getopt\n",
    "import shutil\n",
    "import posixpath\n",
    "import lxml.etree\n",
    "import calendar, time\n",
    "\n",
    "import urllib.request as urllib2\n",
    "\n",
    "#-- PURPOSE: check internet connection\n",
    "def check_connection():\n",
    "    #-- attempt to connect to public http Polar Geospatial Center host\n",
    "    try:\n",
    "        urllib2.urlopen('http://data.pgc.umn.edu/elev/dem/', timeout=1)\n",
    "    except urllib2.URLError:\n",
    "        raise RuntimeError('Check internet connection')\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- PURPOSE: sync local ArcticDEM files with PGC public server\n",
    "def pgc_arcticdem_sync(DIRECTORY, VERSION, RESOLUTION, TILES=None,\n",
    "    LOG=False, LIST=False, CLOBBER=False, MODE=None):\n",
    "    #-- recursively create data directory if not presently existing\n",
    "    os.makedirs(DIRECTORY,MODE) if not os.path.exists(DIRECTORY) else None\n",
    "    #-- create log file with list of synchronized files (or print to terminal)\n",
    "    if LOG:\n",
    "        #-- output to log file\n",
    "        #-- format: PGC_ArcticDEM_sync_2002-04-01.log\n",
    "        today = time.strftime('%Y-%m-%d',time.localtime())\n",
    "        LOGFILE = 'PGC_ArcticDEM_sync_{0}.log'.format(today)\n",
    "        fid = open(os.path.join(DIRECTORY,LOGFILE),'w')\n",
    "        print('PGC ArcticDEM Sync Log ({0})'.format(today), file=fid)\n",
    "        print('VERSION={0}'.format(VERSION), file=fid)\n",
    "        print('RESOLUTION={0}'.format(RESOLUTION), file=fid)\n",
    "        print('TILES={0}'.format(','.join(TILES)), file=fid) if TILES else None\n",
    "    else:\n",
    "        #-- standard output (terminal output)\n",
    "        fid = sys.stdout\n",
    "\n",
    "    #-- remote http server for PGC DEM data\n",
    "    HOST = posixpath.join('http://data.pgc.umn.edu','elev','dem','setsm')\n",
    "    #-- compile regular expression operators for tiles\n",
    "    R1 = re.compile('|'.join(TILES)) if TILES else re.compile('\\d+_\\d+')\n",
    "    R2 = re.compile('(\\d+_\\d+)_(.*?)\\.tar\\.gz')\n",
    "    #-- compile regular expression operators for shapefiles\n",
    "    R3 = re.compile('(.*?)_Tile_Index_Rel(\\d+)\\.zip')\n",
    "\n",
    "    #-- compile HTML parser for lxml\n",
    "    parser = lxml.etree.HTMLParser()\n",
    "\n",
    "    #-- remote directory for data version and resolution\n",
    "    remote_dir = posixpath.join(HOST,'ArcticDEM','mosaic',VERSION,RESOLUTION)\n",
    "    #-- open connection with PGC server at remote directory\n",
    "    request = urllib2.Request(remote_dir)\n",
    "    response = urllib2.urlopen(request, timeout=20)\n",
    "    #-- read and parse request for files (names and modified dates)\n",
    "    tree = lxml.etree.parse(response, parser)\n",
    "    colnames = tree.xpath('//td[@class=\"indexcolname\"]//a/@href')\n",
    "    collastmod = tree.xpath('//td[@class=\"indexcollastmod\"]/text()')\n",
    "    remote_sub = sorted([d for i,d in enumerate(colnames) if R1.match(d)])\n",
    "    #-- for each tile subdirectory\n",
    "    for sd in remote_sub:\n",
    "        #-- check if data directory exists and recursively create if not\n",
    "        local_dir = os.path.join(DIRECTORY,sd)\n",
    "        if not os.access(local_dir, os.F_OK) and not LIST:\n",
    "            os.makedirs(local_dir,MODE)\n",
    "        #-- open connection with PGC server at remote directory\n",
    "        request = urllib2.Request(posixpath.join(remote_dir,sd))\n",
    "        response = urllib2.urlopen(request, timeout=20)\n",
    "        #-- read and parse request for files (names and modified dates)\n",
    "        tree = lxml.etree.parse(response, parser)\n",
    "        colnames = tree.xpath('//td[@class=\"indexcolname\"]//a/@href')\n",
    "        collastmod = tree.xpath('//td[@class=\"indexcollastmod\"]/text()')\n",
    "        remote_file_lines = [i for i,f in enumerate(colnames) if R2.match(f)]\n",
    "        #-- sync each ArcticDEM data file\n",
    "        for i in remote_file_lines:\n",
    "            #-- remote and local versions of the file\n",
    "            remote_file = posixpath.join(remote_dir,sd,colnames[i])\n",
    "            local_file = os.path.join(local_dir,colnames[i])\n",
    "            #-- get last modified date and convert into unix time\n",
    "            lastmodtime = time.strptime(collastmod[i].rstrip(),'%Y-%m-%d %H:%M')\n",
    "            remote_mtime = calendar.timegm(lastmodtime)\n",
    "            #-- sync ArcticDEM tar file\n",
    "            http_pull_file(fid, remote_file, remote_mtime, local_file, LIST,\n",
    "                CLOBBER, MODE)\n",
    "        #-- close request\n",
    "        request = None\n",
    "\n",
    "    #-- remote directory for shapefiles of data version\n",
    "    remote_dir = posixpath.join(HOST,'ArcticDEM','indexes')\n",
    "    #-- open connection with PGC server at remote directory\n",
    "    request = urllib2.Request(remote_dir)\n",
    "    response = urllib2.urlopen(request, timeout=20)\n",
    "    #-- read and parse request for files (names and modified dates)\n",
    "    tree = lxml.etree.parse(response, parser)\n",
    "    colnames = tree.xpath('//td[@class=\"indexcolname\"]//a/@href')\n",
    "    collastmod = tree.xpath('//td[@class=\"indexcollastmod\"]/text()')\n",
    "    remote_file_lines = [i for i,d in enumerate(colnames) if R3.match(d)]\n",
    "    #-- sync each ArcticDEM shapefile\n",
    "    for i in remote_file_lines:\n",
    "        #-- remote and local versions of the file\n",
    "        remote_file = posixpath.join(remote_dir,colnames[i])\n",
    "        local_file = os.path.join(DIRECTORY,colnames[i])\n",
    "        #-- get last modified date and convert into unix time\n",
    "        lastmodtime = time.strptime(collastmod[i].rstrip(),'%Y-%m-%d %H:%M')\n",
    "        remote_mtime = calendar.timegm(lastmodtime)\n",
    "        #-- sync ArcticDEM shapefile\n",
    "        http_pull_file(fid, remote_file, remote_mtime, local_file, LIST,\n",
    "            CLOBBER, MODE)\n",
    "\n",
    "    #-- close log file and set permissions level to MODE\n",
    "    if LOG:\n",
    "        fid.close()\n",
    "        os.chmod(os.path.join(DIRECTORY,LOGFILE), MODE)\n",
    "\n",
    "#-- PURPOSE: pull file from a remote host checking if file exists locally\n",
    "#-- and if the remote file is newer than the local file\n",
    "def http_pull_file(fid,remote_file,remote_mtime,local_file,LIST,CLOBBER,MODE):\n",
    "    #-- if file exists in file system: check if remote file is newer\n",
    "    TEST = False\n",
    "    OVERWRITE = ' (clobber)'\n",
    "    #-- check if local version of file exists\n",
    "    if os.access(local_file, os.F_OK):\n",
    "        #-- check last modification time of local file\n",
    "        local_mtime = os.stat(local_file).st_mtime\n",
    "        #-- if remote file is newer: overwrite the local file\n",
    "        if (remote_mtime > local_mtime):\n",
    "            TEST = True\n",
    "            OVERWRITE = ' (overwrite)'\n",
    "    else:\n",
    "        TEST = True\n",
    "        OVERWRITE = ' (new)'\n",
    "    #-- if file does not exist locally, is to be overwritten, or CLOBBER is set\n",
    "    if TEST or CLOBBER:\n",
    "        #-- Printing files transferred\n",
    "        print('{0} --> '.format(remote_file), file=fid)\n",
    "        print('\\t{0}{1}\\n'.format(local_file,OVERWRITE), file=fid)\n",
    "        #-- if executing copy command (not only printing the files)\n",
    "        if not LIST:\n",
    "            #-- Create and submit request. There are a wide range of exceptions\n",
    "            #-- that can be thrown here, including HTTPError and URLError.\n",
    "            request = urllib2.Request(remote_file)\n",
    "            response = urllib2.urlopen(request, timeout=20)\n",
    "            #-- chunked transfer encoding size\n",
    "            CHUNK = 16 * 1024\n",
    "            #-- copy contents to local file using chunked transfer encoding\n",
    "            #-- transfer should work properly with ascii and binary data formats\n",
    "            with open(local_file, 'wb') as f:\n",
    "                shutil.copyfileobj(response, f, CHUNK)\n",
    "            #-- keep remote modification time of file and local access time\n",
    "            os.utime(local_file, (os.stat(local_file).st_atime, remote_mtime))\n",
    "            os.chmod(local_file, MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/mosaic/v3.0/2m/43_08/43_08_1_1_2m_v3.0.tar.gz --> \n",
      "\t/home/jovyan/glaciersat2/43_08/43_08_1_1_2m_v3.0.tar.gz (new)\n",
      "\n",
      "http://data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/mosaic/v3.0/2m/43_08/43_08_1_2_2m_v3.0.tar.gz --> \n",
      "\t/home/jovyan/glaciersat2/43_08/43_08_1_2_2m_v3.0.tar.gz (new)\n",
      "\n",
      "http://data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/mosaic/v3.0/2m/43_08/43_08_2_1_2m_v3.0.tar.gz --> \n",
      "\t/home/jovyan/glaciersat2/43_08/43_08_2_1_2m_v3.0.tar.gz (new)\n",
      "\n",
      "http://data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/mosaic/v3.0/2m/43_08/43_08_2_2_2m_v3.0.tar.gz --> \n",
      "\t/home/jovyan/glaciersat2/43_08/43_08_2_2_2m_v3.0.tar.gz (new)\n",
      "\n",
      "http://data.pgc.umn.edu/elev/dem/setsm/ArcticDEM/indexes/ArcticDEM_Tile_Index_Rel7.zip --> \n",
      "\t/home/jovyan/glaciersat2/ArcticDEM_Tile_Index_Rel7.zip (new)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "LIST = False\n",
    "LOG = False\n",
    "CLOBBER = False\n",
    "#-- ArcticDEM parameters\n",
    "VERSION = 'v3.0'\n",
    "RESOLUTION = '2m'\n",
    "# tile for Kaskawulsh\n",
    "TILES = ['43_08']\n",
    "#-- permissions mode of the local directories and files (number in octal)\n",
    "MODE = 0o775\n",
    "\n",
    "\n",
    "#-- check internet connection before attempting to run program\n",
    "pgc_arcticdem_sync(DIRECTORY, VERSION, RESOLUTION, TILES=TILES,\n",
    "                   LIST=LIST, LOG=LOG, CLOBBER=CLOBBER, MODE=MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/glaciersat2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
